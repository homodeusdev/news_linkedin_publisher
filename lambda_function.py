import os
import requests
import openai
import logging
from dotenv import load_dotenv
from datetime import datetime
import random
import json
import re
from typing import List

# Cargar variables de entorno desde .env (para desarrollo local)
load_dotenv()

# Obtener claves y tokens desde variables de entorno
NEWSAPI_KEY = os.environ.get("NEWSAPI_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
LINKEDIN_ACCESS_TOKEN = os.environ.get("LINKEDIN_ACCESS_TOKEN")
LINKEDIN_PERSON_ID = os.environ.get("LINKEDIN_PERSON_ID")

openai.api_key = os.environ.get("OPENAI_API_KEY")


# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Archivo temporal para art√≠culos publicados en Lambda
PUBLISHED_ARTICLES_FILE = "/tmp/published_articles.txt"

def is_already_published(url):
    if not os.path.exists(PUBLISHED_ARTICLES_FILE):
        return False
    with open(PUBLISHED_ARTICLES_FILE, "r") as f:
        return url.strip() in [line.strip() for line in f.readlines()]

def mark_as_published(url):
    with open(PUBLISHED_ARTICLES_FILE, "a") as f:
        f.write(url.strip() + "\n")

# Rotaci√≥n tem√°tica semanal de bloques (5 bloques, uno por d√≠a laboral)
CATEGORY_BLOCKS = [
    # Bloque 1 ‚Äì Inteligencia Artificial y automatizaci√≥n
    [
        "Artificial Intelligence",
        "Machine Learning",
        "Deep Learning",
        "Natural Language Processing",
        "Computer Vision",
        "Generative AI",
        "Prompt Engineering",
    ],
    # Bloque 2 ‚Äì Aplicaciones de IA y √âtica
    [
        "AI Agents & Automation",
        "AI Ethics & Regulation",
        "Human-AI Interaction",
        "Robotics",
        "Business Strategy in AI Era",
        "Green Tech with AI",
    ],
    # Bloque 3 ‚Äì Ciencia y Tecnolog√≠a Emergente
    [
        "Scientific Breakthroughs",
        "Quantum Computing",
        "Neuroscience & AI",
        "Emerging Technologies",
        "Cloud Computing",
        "Edge AI",
        "Tech Policy & Regulation",
    ],
    # Bloque 4 ‚Äì FinTech y econom√≠a digital
    [
        "FinTech",
        "InsurTech",
        "HealthTech",
        "RegTech",
        "Cybersecurity",
        "Blockchain",
        "AI Startups & Innovation",
    ],
    # Bloque 5 ‚Äì Econom√≠a y FinTech en M√©xico
    [
        "Econom√≠a M√©xico",
        "Finanzas Personales MX",
        "FinTech M√©xico",
        "Pagos Digitales MX",
        "Banca Digital M√©xico",
        "Inclusi√≥n Financiera MX",
        "Cripto en M√©xico",
        "CNBV Regulaci√≥n",
        "Startups Financieras MX",
    ],
]

# Palabras gatillo para calcular controversy_score
CONTROVERSY_KEYWORDS = [

    # Bloque 1 ‚Äì IA y Automatizaci√≥n
    "sesgo", "bias",
    "desempleo", "job loss", "layoff", "automation layoffs",
    "deepfake", "deep fake",
    "killer robot", "killer robots",
    "privacy", "privacidad", "vigilancia", "surveillance",
    "copyright", "plagio", "lawsuit", "demanda",
    "monopolio", "monopoly",
    "agencia reguladora", "regulatory body",
    "AGI", "superinteligencia",
    "data leak", "filtraci√≥n de datos",

    # Bloque 2 ‚Äì Aplicaciones de IA, √âtica y Robots
    "√©tica", "ethics", "regulaci√≥n", "regulation", "barrera legal",
    "responsabilidad", "liability",
    "malfunction", "accidente", "fatal", "fatality",
    "robots reemplazan", "robots replace",

    # Bloque 3 ‚Äì Tech emergente y ciencia
    "breakthrough controvertido",
    "quantum threat", "breaking encryption", "cripto-quiebre",
    "biohack", "bio-hacking", "edici√≥n gen√©tica", "gene editing",
    "neuromarketing", "implante cerebral", "brain implant",
    "colapso", "cat√°strofe", "catastrophic", "existential risk",

    # Bloque 4 ‚Äì FinTech global y econom√≠a digital
    "fraude", "fraud", "phishing", "estafa", "scam",
    "hack", "breach", "data breach",
    "ransomware", "secuestro de datos",
    "lavado de dinero", "money laundering",
    "multas", "fine", "penalty",
    "bancarrota", "bankruptcy", "chapter 11",
    "burbuja", "bubble", "crash", "colapso burs√°til",
    "regulaci√≥n SEC", "SEC lawsuit", "KYC fail",

    # Bloque 5 ‚Äì Econom√≠a y FinTech en M√©xico
    "CNBV", "Banxico", "superpeso", "devaluaci√≥n", "inflaci√≥n", "inflation",
    "alza de tasas", "raise rates", "tasa de inter√©s", "interest rate",
    "moratoria", "default", "impago",
    "corrupci√≥n", "corrupcion",
    "fraude piramidal", "esquema ponzi", "ponzi scheme",
    "apag√≥n bancario", "bank outage",
    "ciberataque", "cyberattack",
    "reforma fiscal", "tax reform"
]

def select_category():
    """
    Selecciona una categor√≠a pseudo‚Äëaleatoria basada en el d√≠a de la semana.
    L‚ÄëV: cada d√≠a corresponde a uno de los 5 bloques; S‚ÄëD elige bloque al azar.
    """
    day_of_week = datetime.now().weekday()  # Monday = 0 ‚Ä¶ Sunday = 6
    if day_of_week < 5:
        block_index = day_of_week
    else:
        block_index = random.randint(0, 4)  # Fin de semana

    block = CATEGORY_BLOCKS[block_index]
    return random.choice(block)

def fetch_news():
    """
    Obtiene noticias usando NewsAPI para la categor√≠a seleccionada del d√≠a.
    Se incluyen palabras clave generales para ampliar el alcance.
    """
    category = select_category()
    logger.info(f"Categor√≠a seleccionada para hoy: {category}")
    url = "https://newsapi.org/v2/everything"

    # Detect if topic is explicitly about Mexico/FinTech MX
    is_mexico_topic = ("MX" in category) or ("M√©xico" in category) or ("Mexico" in category)
    language = "es" if is_mexico_topic else "en"
    query = f"{category}" if not is_mexico_topic else f"{category} OR M√©xico OR Mexico"

    params = {
        "q": query,
        "language": language,
        "sortBy": "relevancy",
        "apiKey": NEWSAPI_KEY,
        "pageSize": 5
    }

    # Prioritize Mexican financial outlets when relevant
    MX_DOMAINS = "elfinanciero.com.mx,expansion.mx,forbes.com.mx,eleconomista.com.mx"
    if is_mexico_topic:
        params["domains"] = MX_DOMAINS

    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        articles = data.get("articles", [])
        logger.info(f"Se encontraron {len(articles)} art√≠culos para la categor√≠a {category}.")
        return articles
    else:
        logger.error(f"Error al obtener noticias: {response.status_code} {response.text}")
        return []

def fetch_image_for_article(article):
    """
    Busca una imagen alusiva para la noticia usando Unsplash API, bas√°ndose en el t√≠tulo.
    Devuelve un diccionario con la URL de la imagen y el nombre del autor, o None si no se encuentra.
    """
    search_query = f"minimalist {article.get('title', '')}"
    url = "https://api.unsplash.com/search/photos"
    params = {
         "query": search_query,
         "per_page": 1
    }
    unsplash_key = os.environ.get("UNSPLASH_ACCESS_KEY")
    if not unsplash_key:
        logger.error("UNSPLASH_ACCESS_KEY no est√° configurado en las variables de entorno.")
        return None
    headers = {"Authorization": f"Client-ID {unsplash_key}"}
    response = requests.get(url, params=params, headers=headers)
    if response.status_code == 200:
         data = response.json()
         results = data.get("results", [])
         if results:
              image_url = results[0].get("urls", {}).get("regular", "")
              author_name = results[0].get("user", {}).get("name", "")
              return {"image_url": image_url, "author_name": author_name}
    else:
         logger.error(f"Error al buscar imagen en Unsplash: {response.status_code} {response.text}")
    return None

def summarize_and_rewrite(article):
    content = article.get('description', '')
    if len(content.strip()) < 50:
        return article.get('description', 'Not enough content to generate a summary.')
    
    prompt = (
        "Eres un escritor galardonado de noticias tecnol√≥gicas, mexicano, ingeniero en inteligencia artificial de 40 a√±os, "
        "con un estilo millennial, provocador, c√°lido y que disfruta escribir con un toque de humor, iron√≠a y mucha claridad. "
        "Tus publicaciones deben conectar con una audiencia de profesionales tech mexicanos y latinoamericanos en LinkedIn.\n\n"
        "üìå OBJETIVO: Generar un post de entre 1‚ÄØ200 y 2‚ÄØ000 caracteres (200‚Äë300 palabras) que mantenga la atenci√≥n y fomente conversaci√≥n.\n\n"
        "1Ô∏è‚É£ Comienza con un GANCHO de m√°ximo dos l√≠neas (pregunta retadora, dato impactante o chiste) para atrapar al lector.\n"
        "2Ô∏è‚É£ Desarrolla la historia en p√°rrafos cortos (3‚Äë5 ideas clave) usando emojis y MAY√öSCULAS o guiones visuales para resaltar puntos.\n"
        "3Ô∏è‚É£ Incluye UNO O DOS datos concretos (estad√≠sticas, cifras o citas) antes del cierre, ya sea en p√°rrafo aparte o en bullets.\n"
        "4Ô∏è‚É£ Finaliza con una pregunta provocadora que invite a comentar.\n\n"
        "Si la noticia trata de econom√≠a o FinTech, explica por qu√© impacta al ecosistema financiero mexicano (regulaci√≥n, inversi√≥n, usuarios).\n\n"
        "NO comiences el texto con el t√≠tulo original de la noticia ni lo pongas como encabezado; si lo deseas, int√©gralo de forma natural dentro del cuerpo.\n"
        "NO uses asteriscos para destacar texto. Evita tecnicismos excesivos; busca claridad.\n\n"
        "Genera EXACTAMENTE entre 3 y 5 hashtags relevantes en espa√±ol (sin repetir '#IA') colocados al final del post, en la misma l√≠nea.\n\n"
        "Esta es la descripci√≥n de la noticia sobre la cual debes escribir:\n\n" + content
    )
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a professional tech news writer."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        summary = response.choices[0].message.content.strip()
        return summary
    except Exception as e:
        logger.error(f"Error al resumir el art√≠culo: {e}")
        return "Error generating summary üò¢."

def controversy_score(article: dict) -> int:
    """
    Returns a score 0‚Äë5 based on how many controversy keywords appear
    in the title or description.
    """
    full_text = (article.get("title", "") + " " + article.get("description", "")).lower()
    hits = sum(1 for kw in CONTROVERSY_KEYWORDS if kw.lower() in full_text)
    return min(hits, 5)

def generate_poll(summary: str) -> tuple[str, List[str]]:
    """
    Use OpenAI to generate a poll question and 3‚Äë4 short options.
    Falls back to a default poll if parsing fails.
    """
    poll_prompt = (
        "Devuelve en JSON con keys 'question' y 'options' (lista de 3‚Äë4 elementos ‚â§30 caracteres) "
        "una encuesta para LinkedIn basada en este texto:\n\n" + summary
    )
    try:
        res = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": poll_prompt}],
            max_tokens=150,
            temperature=0.7
        )
        match = re.search(r'\{.*\}', res.choices[0].message.content, re.S)
        data = json.loads(match.group(0)) if match else {}
        question = data.get("question") or "¬øQu√© opinas?"
        options = data.get("options") or ["S√≠", "No", "Tal vez"]
    except Exception as e:
        logger.error(f"Error generando poll: {e}")
        question, options = "¬øQu√© opinas?", ["S√≠", "No", "Tal vez"]
    return question, options[:4]

def post_to_linkedin_poll(commentary: str, poll_question: str, poll_options: List[str]):
    url = "https://api.linkedin.com/rest/posts"
    headers = {
        "Authorization": f"Bearer {LINKEDIN_ACCESS_TOKEN}",
        "Content-Type": "application/json",
        "LinkedIn-Version": "202506",
        "X-Restli-Protocol-Version": "2.0.0"
    }
    payload = {
        "author": f"urn:li:person:{LINKEDIN_PERSON_ID}",
        "commentary": commentary,
        "visibility": "PUBLIC",
        "distribution": {
            "feedDistribution": "MAIN_FEED",
            "targetEntities": [],
            "thirdPartyDistributionChannels": []
        },
        "lifecycleState": "PUBLISHED",
        "content": {
            "poll": {
                "question": poll_question,
                "options": [{"text": opt[:30]} for opt in poll_options],
                "settings": {"duration": "THREE_DAYS"}
            }
        }
    }
    res = requests.post(url, headers=headers, json=payload)
    if res.status_code == 201:
        logger.info("Encuesta publicada con √©xito ‚úÖ")
    else:
        logger.error(f"Error publicando encuesta: {res.status_code} {res.text}")

def post_to_linkedin_shares(content, image_url=None):
    logger.info(f"Preparando publicaci√≥n: {content[:100]}...")

    url = "https://api.linkedin.com/v2/shares"
    headers = {
        "Authorization": f"Bearer {LINKEDIN_ACCESS_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "owner": f"urn:li:person:{LINKEDIN_PERSON_ID}",
        "text": {"text": content}
    }

    if image_url:
        payload["content"] = {
            "contentEntities": [
                {
                    "entityLocation": image_url,
                    "thumbnails": [{"resolvedUrl": image_url}],
                    "altText": "Imagen alusiva a la noticia"
                }
            ],
            "title": "Imagen relacionada"
        }

    response = requests.post(url, headers=headers, json=payload)
    if response.status_code == 201:
        logger.info("Publicaci√≥n en LinkedIn (Shares) realizada con √©xito ‚úÖ.")
    else:
        logger.error(f"Error al publicar en LinkedIn (Shares): {response.status_code} {response.text}")

def main():
    articles = fetch_news()
    logger.info(f"Art√≠culos obtenidos: {len(articles) if articles else 0}")
    if not articles:
        return

    processed = []  # list of tuples (score, article, summary, image_info)
    for art in articles:
        if is_already_published(art["url"]):
            logger.info(f"Art√≠culo ya publicado, se omite: {art['url']}")
            continue
        summary = summarize_and_rewrite(art)
        score = controversy_score(art)
        img_info = fetch_image_for_article(art)
        processed.append((score, art, summary, img_info))

    if not processed:
        return

    # Selecciona la noticia con mayor controversia
    top_tuple = max(processed, key=lambda x: x[0])
    top_score, top_art, top_summary, top_img = top_tuple

    for score, art, summary, img_info in processed:
        content = f"{summary}\n\nFuente üëâ {art['url']}"
        author_credit = (
            f"\nüì∏ Imagen de {img_info['author_name']} v√≠a Unsplash"
            if img_info and img_info.get("author_name") else ""
        )
        if art == top_art and score > 0:
            # Publica encuesta
            q, opts = generate_poll(summary)
            post_to_linkedin_poll(content, q, opts)
        else:
            # Publica share normal
            img_url = img_info.get("image_url") if img_info else None
            post_to_linkedin_shares(content + author_credit, image_url=img_url)

        mark_as_published(art["url"])

def lambda_handler(event, context):
    main()
    return {
        "statusCode": 200,
        "body": "Ejecuci√≥n finalizada correctamente."
    }